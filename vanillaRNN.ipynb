{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/N4tth/taller2-RN/blob/main/vanillaRNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "a6VGUISK_9HK"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "import itertools\n",
        "import pandas as pd\n",
        "import kagglehub\n",
        "import requests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Character-level language modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhHmpmyCrdUA",
        "outputId": "7cca8049-e8aa-4e0f-969d-d65931514746"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ruta del dataset descargado: C:\\Users\\laura\\.cache\\kagglehub\\datasets\\new-york-city\\nyc-dog-names\\versions\\1\n",
            "Dataset cargado correctamente\n",
            "Shape: (16220, 2)\n",
            "Columnas: ['Row_Labels', 'Count_AnimalName']\n",
            "  Row_Labels  Count_AnimalName\n",
            "0          1                 1\n",
            "1          2                 2\n",
            "2      40804                 1\n",
            "3      90201                 1\n",
            "4      90203                 1\n"
          ]
        }
      ],
      "source": [
        "#load dataset\n",
        "dataset_path = kagglehub.dataset_download(\"new-york-city/nyc-dog-names\")\n",
        "print(\"Ruta del dataset descargado:\", dataset_path)\n",
        "\n",
        "for f in os.listdir(dataset_path):\n",
        "    if f.endswith(\".csv\"):\n",
        "        csv_path = os.path.join(dataset_path, f)\n",
        "        break\n",
        "\n",
        "\n",
        "df = pd.read_csv(csv_path)\n",
        "print(\"Dataset cargado correctamente\")\n",
        "\n",
        "print(\"Shape:\", df.shape)\n",
        "print(\"Columnas:\", df.columns.tolist())\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6Cqk1EwkOFG",
        "outputId": "5de192c4-5e5f-407b-cf39-c0de17fb9497"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columnas limpias:  ['Row_Labels', 'Count_AnimalName']\n",
            "Usando columnas → Nombres: Row_Labels, Conteos: Count_AnimalName\n",
            "total nombres limpios: 43391\n",
            "Ejemplos:  ['march', 'march', 'april', 'april', 'april', 'april', 'april', 'april', 'april', 'april']\n",
            "Longitud total del texto: 290009 carácteres\n",
            "Num caracteres únicos: 33\n",
            "Ejemplos vocabulario: ['\\n', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's']\n"
          ]
        }
      ],
      "source": [
        "#Preprocessing\n",
        "df.columns = df.columns.str.strip()\n",
        "df.columns = df.columns.str.replace(r'[^a-zA-Z0-9_#]+', '', regex=True)\n",
        "print(\"Columnas limpias: \", df.columns.tolist())\n",
        "\n",
        "col_name = None\n",
        "col_count = None\n",
        "\n",
        "for c in df.columns:\n",
        "  if \"row\" in c.lower():\n",
        "      col_name = c\n",
        "  if \"count\" in c.lower():\n",
        "    col_count = c\n",
        "if not col_name or not col_count:\n",
        "  raise ValueError(\"No se encontraron columnas de nombres o conteo\")\n",
        "print(f\"Usando columnas → Nombres: {col_name}, Conteos: {col_count}\")\n",
        "\n",
        "names = df[col_name].dropna().astype(str).tolist()\n",
        "counts = df[col_count].fillna(1).astype(int).tolist()\n",
        "\n",
        "clean_names = []\n",
        "for name, count in zip(names, counts):\n",
        "  name = name.lower().strip()\n",
        "  name = re.sub(r'[^a-zñáéíóú ]', '', name)\n",
        "  if 2 <= len(name) <=12:\n",
        "    repetitions = min(count, 10)\n",
        "    clean_names.extend([name] * repetitions)\n",
        "print(f\"total nombres limpios: {len(clean_names)}\")\n",
        "print(\"Ejemplos: \", clean_names[:10])\n",
        "#Corpus\n",
        "text = \"\\n\".join(clean_names)\n",
        "print(f\"Longitud total del texto: {len(text)} carácteres\")\n",
        "\n",
        "#Tokenization\n",
        "chars = sorted(list(set(text)))\n",
        "char_to_int = {ch:i for i, ch in enumerate(chars)}\n",
        "int_to_char = {i: ch for i, ch in enumerate(chars)}\n",
        "vocab_size = len(chars)\n",
        "\n",
        "print(f\"Num caracteres únicos: {vocab_size}\")\n",
        "print(\"Ejemplos vocabulario:\", chars[:20])\n",
        "\n",
        "def get_subset_text(text, size):\n",
        "  if len(text) < size:\n",
        "    size = len(text)\n",
        "  return text[:size]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQW8UeniaWYv"
      },
      "source": [
        "seq_length. Que es el número de neuronas recurrentes. 64, 128, 256\n",
        "words. Tamaño del conjunto de datos. 5000, 20000, 50000\n",
        "max_iter. Número de iteraciones/época. 30, 50, 80\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Un7xfnnNIaJu"
      },
      "outputs": [],
      "source": [
        "#experiment configurations\n",
        "seq_lengths = [64, 128, 256]\n",
        "dataset_sizes = [5000, 20000, 50000]\n",
        "max_iters = [30, 50, 80]\n",
        "clip_options = [True, False]\n",
        "\n",
        "experiments = list(itertools.product(seq_lengths, dataset_sizes, max_iters, clip_options))\n",
        "results = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Word-level language modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be done: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor\n"
          ]
        }
      ],
      "source": [
        "#load dataset\n",
        "URL = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
        "text_shakespeare = requests.get(URL).text\n",
        "print(text_shakespeare[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Palabras totales: 203839\n",
            "Palabras únicas (vocab_size): 12373\n",
            "Ejemplos de tokens: ['first', 'citizen', 'before', 'we', 'proceed', 'any', 'further', 'hear', 'me', 'speak', 'all', 'speak', 'speak', 'first', 'citizen', 'you', 'are', 'all', 'resolved', 'rather']\n",
            "Ejemplos de secuencia codificada: [4080, 1879, 894, 11907, 8203, 431, 4464, 5043, 6603, 9946, 295, 9946, 9946, 4080, 1879, 12348, 509, 295, 8825, 8541]\n"
          ]
        }
      ],
      "source": [
        "#preprocessing\n",
        "text_shakespeare = text_shakespeare.lower().replace('\\r', ' ').replace('\\n', ' ')\n",
        "tokens_shakespeare = re.findall(r\"[a-z]+'?[a-z]+|[a-z]+\", text_shakespeare)\n",
        "vocab = sorted(set(tokens_shakespeare))\n",
        "word_to_int = {w: i for i, w in enumerate(vocab)}\n",
        "int_to_word = {i: w for w, i in word_to_int.items()}\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "print(f\"Palabras totales: {len(tokens_shakespeare)}\")\n",
        "print(f\"Palabras únicas (vocab_size): {vocab_size}\")\n",
        "print(\"Ejemplos de tokens:\", tokens_shakespeare[:20])\n",
        "\n",
        "encoded = [word_to_int[w] for w in tokens_shakespeare]\n",
        "print(\"Ejemplos de secuencia codificada:\", encoded[:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "#experiment configurations\n",
        "seq_lengths_shakespeare = [64, 128, 256]\n",
        "dataset_sizes_shakespeare = [5000, 20000, 50000]\n",
        "max_iters_shakespeare = [30, 50, 80]\n",
        "clip_options_shakespeare = [True, False]\n",
        "\n",
        "experiments_shakespeare = list(itertools.product(seq_lengths_shakespeare, dataset_sizes_shakespeare, max_iters_shakespeare, clip_options_shakespeare))\n",
        "results_shakespeare = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Vanilla Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "dmFuWWCShRGh"
      },
      "outputs": [],
      "source": [
        "#Vanilla neural network from https://lucyliu-ucsb.github.io/posts/Backpropagation-of-a-vanilla-RNN with modifications\n",
        "class VanillaRNN:\n",
        "    def __init__(self, n_x, n_h, seq_length, learning_rate):\n",
        "        self.n_x = n_x\n",
        "        self.n_h = n_h\n",
        "        self.seq_length = seq_length\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "        self.Wxh = np.random.randn(n_h, n_x) * 0.01\n",
        "        self.Whh = np.random.randn(n_h, n_h) * 0.01\n",
        "        self.Why = np.random.randn(n_x, n_h) * 0.01\n",
        "        self.bh = np.zeros((n_h, 1))\n",
        "        self.by = np.zeros((n_x, 1))\n",
        "\n",
        "\n",
        "        self.mWxh = np.zeros_like(self.Wxh)\n",
        "        self.mWhh = np.zeros_like(self.Whh)\n",
        "        self.mWhy = np.zeros_like(self.Why)\n",
        "        self.mbh = np.zeros_like(self.bh)\n",
        "        self.mby = np.zeros_like(self.by)\n",
        "\n",
        "    def forward_pass(self, inputs, targets, hprev):\n",
        "        x, h, y, p = {}, {}, {}, {}\n",
        "        h[-1] = np.copy(hprev)\n",
        "        loss = 0\n",
        "\n",
        "        for t in range(len(inputs)):\n",
        "            x[t] = np.zeros((self.n_x, 1))\n",
        "            x[t][inputs[t]] = 1\n",
        "            h[t] = np.tanh(self.Wxh @ x[t] + self.Whh @ h[t-1] + self.bh)\n",
        "            y[t] = self.Why @ h[t] + self.by\n",
        "            p[t] = np.exp(y[t]) / np.sum(np.exp(y[t]))\n",
        "            loss -= np.log(p[t][targets[t], 0])\n",
        "\n",
        "        return loss, x, h, p\n",
        "\n",
        "    def backpropagation(self, x, h, p, targets, clip=True):\n",
        "        dWxh, dWhh, dWhy = np.zeros_like(self.Wxh), np.zeros_like(self.Whh), np.zeros_like(self.Why)\n",
        "        dbh, dby = np.zeros_like(self.bh), np.zeros_like(self.by)\n",
        "        dhnext = np.zeros_like(h[0])\n",
        "\n",
        "        for t in reversed(range(self.seq_length)):\n",
        "            dy = np.copy(p[t])\n",
        "            dy[targets[t]] -= 1\n",
        "            dWhy += dy @ h[t].T\n",
        "            dby += dy\n",
        "            dh = self.Why.T @ dy + dhnext\n",
        "            dhraw = (1 - h[t] * h[t]) * dh\n",
        "            dbh += dhraw\n",
        "            dWxh += dhraw @ x[t].T\n",
        "            dWhh += dhraw @ h[t-1].T\n",
        "            dhnext = self.Whh.T @ dhraw\n",
        "\n",
        "        # Clipping enabling. Since there's no interface, the parameter \"clip\" functions as a switch\n",
        "        if clip:\n",
        "            for dparam in [dWxh, dWhh, dWhy, dbh, dby]:\n",
        "                np.clip(dparam, -5, 5, out=dparam)\n",
        "\n",
        "        return dWxh, dWhh, dWhy, dbh, dby\n",
        "\n",
        "    def update_para(self, dWxh, dWhh, dWhy, dbh, dby):\n",
        "        for param, dparam, mem in zip(\n",
        "            ['Wxh', 'Whh', 'Why', 'bh', 'by'],\n",
        "            [dWxh, dWhh, dWhy, dbh, dby],\n",
        "            ['mWxh', 'mWhh', 'mWhy', 'mbh', 'mby']\n",
        "        ):\n",
        "            setattr(self, mem, getattr(self, mem) + dparam * dparam)\n",
        "            setattr(self, param, getattr(self, param) -\n",
        "                    self.learning_rate * dparam / np.sqrt(getattr(self, mem) + 1e-8))\n",
        "\n",
        "    def train(self, text, char_to_int, int_to_char, max_iter=10000, clip=True):\n",
        "        iter_num, pos = 0, 0\n",
        "        loss_list, perplexity_list = [], []\n",
        "        hprev = np.zeros((self.n_h, 1))\n",
        "        loss = -np.log(1.0 / self.n_x) * self.seq_length\n",
        "\n",
        "        while iter_num < max_iter:\n",
        "            if pos + self.seq_length + 1 >= len(text) or iter_num == 0:\n",
        "                hprev = np.zeros((self.n_h, 1))\n",
        "                pos = 0\n",
        "\n",
        "            inputs = [char_to_int[ch] for ch in text[pos:pos+self.seq_length]]\n",
        "            targets = [char_to_int[ch] for ch in text[pos+1:pos+self.seq_length+1]]\n",
        "            pos += self.seq_length\n",
        "\n",
        "            # Forward pass\n",
        "            loss, x, h, p = self.forward_pass(inputs, targets, hprev)\n",
        "            loss_list.append(loss)\n",
        "            #Perplexity\n",
        "            perplexity_list.append(np.exp(loss / self.seq_length))\n",
        "\n",
        "            # Backprop\n",
        "            dWxh, dWhh, dWhy, dbh, dby = self.backpropagation(x, h, p, targets, clip=clip)\n",
        "            self.update_para(dWxh, dWhh, dWhy, dbh, dby)\n",
        "            hprev = h[self.seq_length - 1]\n",
        "\n",
        "            if iter_num % 1000 == 0:\n",
        "                print(f\"Iteración {iter_num} - Loss: {loss:.3f} - Perplejidad: {np.exp(loss/self.seq_length):.3f}\")\n",
        "            iter_num += 1\n",
        "\n",
        "        return loss_list, perplexity_list\n",
        "    def make_sample(self, hprev, seed_ix, n):\n",
        "        \"\"\"\n",
        "        sample a length n sequence from the model\n",
        "        \"\"\"\n",
        "        x = np.zeros((self.n_x, 1))\n",
        "        x[seed_ix] = 1\n",
        "        ixes = []\n",
        "        h = np.copy(hprev)\n",
        "\n",
        "        for t in range(n):\n",
        "            h = np.tanh(self.Wxh @ x + self.Whh @ h + self.bh)\n",
        "            y = self.Why @ h + self.by\n",
        "            p = np.exp(y) / np.sum(np.exp(y))\n",
        "            ix = np.random.choice(range(self.n_x), p = p.ravel())\n",
        "            x = np.zeros((self.n_x, 1))\n",
        "            x[ix] = 1\n",
        "            ixes.append(ix)\n",
        "        return ixes\n",
        "\n",
        "    #Graphs\n",
        "    def plot_loss(self, loss_list):\n",
        "        plt.figure(figsize=(8, 5))\n",
        "        plt.plot(loss_list, label=\"Loss\", color='blue')\n",
        "        plt.title(\"Curva de pérdida vs iteraciones\")\n",
        "        plt.xlabel(\"Iteraciones\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "\n",
        "    def plot_perplexity(self, perplexity_list):\n",
        "        plt.figure(figsize=(8, 5))\n",
        "        plt.plot(perplexity_list, label=\"Perplejidad\", color='orange')\n",
        "        plt.title(\"Curva de perplejidad vs iteraciones\")\n",
        "        plt.xlabel(\"Iteraciones\")\n",
        "        plt.ylabel(\"Perplejidad\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Character-level language modeling experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "F800opOYJqpO",
        "outputId": "8ca1b7b2-9057-4192-92ff-3072bcb6eace"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Entrenando modelo ===\n",
            "seq_length=64, dataset_size=5000, max_iter=30, clip=True\n",
            "Iteración 0 - Loss: 223.797 - Perplejidad: 33.011\n",
            "→ Nombres generados: naaddaerh\n",
            "\n",
            "\n",
            "=== Entrenando modelo ===\n",
            "seq_length=64, dataset_size=5000, max_iter=30, clip=False\n",
            "Iteración 0 - Loss: 223.777 - Perplejidad: 33.000\n",
            "→ Nombres generados: ktpqéwqxsé\n",
            "\n",
            "=== Entrenando modelo ===\n",
            "seq_length=64, dataset_size=5000, max_iter=50, clip=True\n",
            "Iteración 0 - Loss: 223.795 - Perplejidad: 33.009\n",
            "→ Nombres generados: \n",
            "a\n",
            "\n",
            "a\n",
            "a\n",
            "li\n",
            "\n",
            "=== Entrenando modelo ===\n",
            "seq_length=64, dataset_size=5000, max_iter=50, clip=False\n",
            "Iteración 0 - Loss: 223.755 - Perplejidad: 32.989\n",
            "→ Nombres generados: oudeó\n",
            "h\n",
            "ai\n",
            "\n",
            "=== Entrenando modelo ===\n",
            "seq_length=64, dataset_size=5000, max_iter=80, clip=True\n",
            "Iteración 0 - Loss: 223.740 - Perplejidad: 32.981\n",
            "→ Nombres generados: uz\n",
            "lle\n",
            "axr\n",
            "\n",
            "=== Entrenando modelo ===\n",
            "seq_length=64, dataset_size=5000, max_iter=80, clip=False\n",
            "Iteración 0 - Loss: 223.756 - Perplejidad: 32.989\n",
            "→ Nombres generados: m\n",
            "aep\n",
            "abas\n",
            "\n",
            "=== Entrenando modelo ===\n",
            "seq_length=64, dataset_size=20000, max_iter=30, clip=True\n",
            "Iteración 0 - Loss: 223.782 - Perplejidad: 33.003\n",
            "→ Nombres generados: i\n",
            "\n",
            "r\n",
            "rreel\n",
            "\n",
            "=== Entrenando modelo ===\n",
            "seq_length=64, dataset_size=20000, max_iter=30, clip=False\n",
            "Iteración 0 - Loss: 223.747 - Perplejidad: 32.985\n",
            "→ Nombres generados: inóh\n",
            "unsdt\n",
            "\n",
            "=== Entrenando modelo ===\n",
            "seq_length=64, dataset_size=20000, max_iter=50, clip=True\n",
            "Iteración 0 - Loss: 223.753 - Perplejidad: 32.988\n",
            "→ Nombres generados: daybmitorf\n",
            "\n",
            "=== Entrenando modelo ===\n",
            "seq_length=64, dataset_size=20000, max_iter=50, clip=False\n",
            "Iteración 0 - Loss: 223.767 - Perplejidad: 32.995\n",
            "→ Nombres generados: baaanla\n",
            "a\n",
            "\n",
            "\n",
            "=== Entrenando modelo ===\n",
            "seq_length=64, dataset_size=20000, max_iter=80, clip=True\n",
            "Iteración 0 - Loss: 223.777 - Perplejidad: 33.000\n",
            "→ Nombres generados: u\n",
            "aoeíwzps\n",
            "\n",
            "=== Entrenando modelo ===\n",
            "seq_length=64, dataset_size=20000, max_iter=80, clip=False\n",
            "Iteración 0 - Loss: 223.770 - Perplejidad: 32.997\n",
            "→ Nombres generados: dalj\n",
            "llela\n",
            "\n",
            "=== Entrenando modelo ===\n",
            "seq_length=64, dataset_size=50000, max_iter=30, clip=True\n",
            "Iteración 0 - Loss: 223.756 - Perplejidad: 32.989\n",
            "→ Nombres generados: uwdwde\n",
            "ddd\n",
            "\n",
            "=== Entrenando modelo ===\n",
            "seq_length=64, dataset_size=50000, max_iter=30, clip=False\n",
            "Iteración 0 - Loss: 223.800 - Perplejidad: 33.012\n",
            "→ Nombres generados: naaaed\n",
            "tei\n",
            "\n",
            "=== Entrenando modelo ===\n",
            "seq_length=64, dataset_size=50000, max_iter=50, clip=True\n",
            "Iteración 0 - Loss: 223.782 - Perplejidad: 33.003\n",
            "→ Nombres generados: \n",
            "\n",
            "aebaitda\n",
            "\n",
            "=== Entrenando modelo ===\n",
            "seq_length=64, dataset_size=50000, max_iter=50, clip=False\n",
            "Iteración 0 - Loss: 223.794 - Perplejidad: 33.009\n",
            "→ Nombres generados: \n",
            "deine\n",
            "aoe\n",
            "\n",
            "=== Entrenando modelo ===\n",
            "seq_length=64, dataset_size=50000, max_iter=80, clip=True\n",
            "Iteración 0 - Loss: 223.803 - Perplejidad: 33.014\n",
            "→ Nombres generados: \n",
            "aa\n",
            "a\n",
            "iiau\n",
            "\n",
            "=== Entrenando modelo ===\n",
            "seq_length=64, dataset_size=50000, max_iter=80, clip=False\n",
            "Iteración 0 - Loss: 223.779 - Perplejidad: 33.001\n",
            "→ Nombres generados: d\n",
            "alyn\n",
            "al\n",
            "\n",
            "\n",
            "=== Entrenando modelo ===\n",
            "seq_length=128, dataset_size=5000, max_iter=30, clip=True\n",
            "Iteración 0 - Loss: 447.562 - Perplejidad: 33.002\n",
            "→ Nombres generados: anúáiiisqs\n",
            "\n",
            "=== Entrenando modelo ===\n",
            "seq_length=128, dataset_size=5000, max_iter=30, clip=False\n",
            "Iteración 0 - Loss: 447.564 - Perplejidad: 33.003\n",
            "→ Nombres generados: qeuyúfbñxk\n",
            "\n",
            "=== Entrenando modelo ===\n",
            "seq_length=128, dataset_size=5000, max_iter=50, clip=True\n",
            "Iteración 0 - Loss: 447.592 - Perplejidad: 33.010\n",
            "→ Nombres generados: e\n",
            "qr\n",
            "yr\n",
            "bi\n",
            "\n",
            "=== Entrenando modelo ===\n",
            "seq_length=128, dataset_size=5000, max_iter=50, clip=False\n",
            "Iteración 0 - Loss: 447.557 - Perplejidad: 33.001\n",
            "→ Nombres generados: róx\n",
            "gjgbzb\n",
            "\n",
            "=== Entrenando modelo ===\n",
            "seq_length=128, dataset_size=5000, max_iter=80, clip=True\n",
            "Iteración 0 - Loss: 447.549 - Perplejidad: 32.999\n",
            "→ Nombres generados: aeul\n",
            "áiaas\n",
            "\n",
            "=== Entrenando modelo ===\n",
            "seq_length=128, dataset_size=5000, max_iter=80, clip=False\n",
            "Iteración 0 - Loss: 447.496 - Perplejidad: 32.985\n",
            "→ Nombres generados: m\n",
            "umoaoiag\n",
            "\n",
            "=== Entrenando modelo ===\n",
            "seq_length=128, dataset_size=20000, max_iter=30, clip=True\n",
            "Iteración 0 - Loss: 447.593 - Perplejidad: 33.010\n",
            "→ Nombres generados: óaamaa\n",
            "aie\n",
            "\n",
            "=== Entrenando modelo ===\n",
            "seq_length=128, dataset_size=20000, max_iter=30, clip=False\n",
            "Iteración 0 - Loss: 447.531 - Perplejidad: 32.994\n",
            "→ Nombres generados: gaualalblj\n",
            "\n",
            "=== Entrenando modelo ===\n",
            "seq_length=128, dataset_size=20000, max_iter=50, clip=True\n",
            "Iteración 0 - Loss: 447.536 - Perplejidad: 32.996\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m rnn = VanillaRNN(n_x=\u001b[38;5;28mlen\u001b[39m(char_to_int), n_h=seq_length, seq_length=seq_length, learning_rate=\u001b[32m0.1\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Entrenamiento\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m loss_list, perplexity_list = \u001b[43mrnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubset_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchar_to_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mint_to_char\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclip\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Generar nombres\u001b[39;00m\n\u001b[32m     12\u001b[39m hprev = np.zeros((rnn.n_h, \u001b[32m1\u001b[39m))\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 93\u001b[39m, in \u001b[36mVanillaRNN.train\u001b[39m\u001b[34m(self, text, char_to_int, int_to_char, max_iter, clip)\u001b[39m\n\u001b[32m     90\u001b[39m perplexity_list.append(np.exp(loss / \u001b[38;5;28mself\u001b[39m.seq_length))\n\u001b[32m     92\u001b[39m \u001b[38;5;66;03m# Backprop\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m dWxh, dWhh, dWhy, dbh, dby = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackpropagation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclip\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[38;5;28mself\u001b[39m.update_para(dWxh, dWhh, dWhy, dbh, dby)\n\u001b[32m     95\u001b[39m hprev = h[\u001b[38;5;28mself\u001b[39m.seq_length - \u001b[32m1\u001b[39m]\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 52\u001b[39m, in \u001b[36mVanillaRNN.backpropagation\u001b[39m\u001b[34m(self, x, h, p, targets, clip)\u001b[39m\n\u001b[32m     50\u001b[39m     dWxh += dhraw @ x[t].T\n\u001b[32m     51\u001b[39m     dWhh += dhraw @ h[t-\u001b[32m1\u001b[39m].T\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     dhnext = \u001b[38;5;28mself\u001b[39m.Whh.T @ dhraw\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# Clipping enabling. Since there's no interface, the parameter \"clip\" functions as a switch\u001b[39;00m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m clip:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "for seq_length, dataset_size, max_iter, clip in experiments:\n",
        "    print(f\"\\n=== Entrenando modelo ===\")\n",
        "    print(f\"seq_length={seq_length}, dataset_size={dataset_size}, max_iter={max_iter}, clip={clip}\")\n",
        "\n",
        "    subset_text = get_subset_text(text, dataset_size)\n",
        "    rnn = VanillaRNN(n_x=len(char_to_int), n_h=seq_length, seq_length=seq_length, learning_rate=0.1)\n",
        "\n",
        "    # Entrenamiento\n",
        "    loss_list, perplexity_list = rnn.train(subset_text, char_to_int, int_to_char, max_iter=max_iter, clip=clip)\n",
        "\n",
        "    # Generar nombres\n",
        "    hprev = np.zeros((rnn.n_h, 1))\n",
        "    seed_ix = np.random.randint(0, len(char_to_int))\n",
        "    sample_ix = rnn.make_sample(hprev, seed_ix, 10)\n",
        "    generated = ''.join(int_to_char[ix] for ix in sample_ix)\n",
        "\n",
        "    print(f\"→ Nombres generados: {generated}\")\n",
        "\n",
        "    results.append({\n",
        "        \"seq_length\": seq_length,\n",
        "        \"dataset_size\": dataset_size,\n",
        "        \"max_iter\": max_iter,\n",
        "        \"clip\": clip,\n",
        "        \"generated\": generated,\n",
        "        \"final_loss\": loss_list[-1],\n",
        "        \"final_perplexity\": perplexity_list[-1]\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Word-level language modeling experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Entrenando modelo (WORD-LEVEL) ===\n",
            "seq_length=64, dataset_size(tokens)=5000, max_iter=30, clip=True\n",
            "→ Texto generado: judases thickest that the swims the fellow famish not the\n",
            "\n",
            "=== Entrenando modelo (WORD-LEVEL) ===\n",
            "seq_length=64, dataset_size(tokens)=5000, max_iter=30, clip=False\n",
            "→ Texto generado: shoes florizel what are true vi for they kings which\n",
            "\n",
            "=== Entrenando modelo (WORD-LEVEL) ===\n",
            "seq_length=64, dataset_size(tokens)=5000, max_iter=50, clip=True\n",
            "→ Texto generado: obstacles proportionable injured or forth he it proud seat capitol\n",
            "\n",
            "=== Entrenando modelo (WORD-LEVEL) ===\n",
            "seq_length=64, dataset_size(tokens)=5000, max_iter=50, clip=False\n",
            "→ Texto generado: flask righteous mere we serpent's mixture in absence unstable is\n",
            "\n",
            "=== Entrenando modelo (WORD-LEVEL) ===\n",
            "seq_length=64, dataset_size(tokens)=5000, max_iter=80, clip=True\n",
            "→ Texto generado: mary's nice much tongue less us made them liking to\n",
            "\n",
            "=== Entrenando modelo (WORD-LEVEL) ===\n",
            "seq_length=64, dataset_size(tokens)=5000, max_iter=80, clip=False\n",
            "→ Texto generado: personally ladders child gods our you on i we marcius\n",
            "\n",
            "=== Entrenando modelo (WORD-LEVEL) ===\n",
            "seq_length=64, dataset_size(tokens)=20000, max_iter=30, clip=True\n",
            "→ Texto generado: applaud citizen account only they i clubs pray the i\n",
            "\n",
            "=== Entrenando modelo (WORD-LEVEL) ===\n",
            "seq_length=64, dataset_size(tokens)=20000, max_iter=30, clip=False\n",
            "→ Texto generado: assemblies to be defended what touching see marcius citizen scabs\n",
            "\n",
            "=== Entrenando modelo (WORD-LEVEL) ===\n",
            "seq_length=64, dataset_size(tokens)=20000, max_iter=50, clip=True\n",
            "→ Texto generado: wave you you dogs you with fool the bloody depends\n",
            "\n",
            "=== Entrenando modelo (WORD-LEVEL) ===\n",
            "seq_length=64, dataset_size(tokens)=20000, max_iter=50, clip=False\n",
            "→ Texto generado: rebuke remember how seeking not me and do glad i'll\n",
            "\n",
            "=== Entrenando modelo (WORD-LEVEL) ===\n",
            "seq_length=64, dataset_size(tokens)=20000, max_iter=80, clip=True\n",
            "→ Texto generado: jule lycurguses solemness darts toes threatening likest need distinguish tiberio\n",
            "\n",
            "=== Entrenando modelo (WORD-LEVEL) ===\n",
            "seq_length=64, dataset_size(tokens)=20000, max_iter=80, clip=False\n",
            "→ Texto generado: manifest for beholding vent babe tick why his my hath\n",
            "\n",
            "=== Entrenando modelo (WORD-LEVEL) ===\n",
            "seq_length=64, dataset_size(tokens)=50000, max_iter=30, clip=True\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 57\u001b[39m\n\u001b[32m     53\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m     55\u001b[39m rnn = VanillaRNN(n_x=vocab_size, n_h=seq_lengths_shakespeare, seq_length=seq_lengths_shakespeare, learning_rate=\u001b[32m0.05\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m loss_list, perplexity_list = \u001b[43mrnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_word\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubset_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_iters_shakespeare\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclip_options_shakespeare\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m hprev = np.zeros((rnn.n_h, \u001b[32m1\u001b[39m))\n\u001b[32m     60\u001b[39m seed_word = \u001b[33m\"\u001b[39m\u001b[33mthe\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mthe\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m word_to_int \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(vocab))\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mtrain_word\u001b[39m\u001b[34m(self, encoded, max_iter, clip)\u001b[39m\n\u001b[32m     17\u001b[39m loss_list.append(loss)\n\u001b[32m     18\u001b[39m perplexity_list.append(np.exp(loss / \u001b[38;5;28mself\u001b[39m.seq_length))\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m dWxh, dWhh, dWhy, dbh, dby = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackpropagation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclip\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;28mself\u001b[39m.update_para(dWxh, dWhh, dWhy, dbh, dby)\n\u001b[32m     21\u001b[39m hprev = h[\u001b[38;5;28mself\u001b[39m.seq_length - \u001b[32m1\u001b[39m]\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 52\u001b[39m, in \u001b[36mVanillaRNN.backpropagation\u001b[39m\u001b[34m(self, x, h, p, targets, clip)\u001b[39m\n\u001b[32m     50\u001b[39m     dWxh += dhraw @ x[t].T\n\u001b[32m     51\u001b[39m     dWhh += dhraw @ h[t-\u001b[32m1\u001b[39m].T\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     dhnext = \u001b[38;5;28mself\u001b[39m.Whh.T @ dhraw\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# Clipping enabling. Since there's no interface, the parameter \"clip\" functions as a switch\u001b[39;00m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m clip:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "def get_subset_tokens(encoded, size):\n",
        "    size = min(size, len(encoded))\n",
        "    return encoded[:size]\n",
        "\n",
        "def train_word(self, encoded, max_iter=10000, clip=True):\n",
        "    iter_num, pos = 0, 0\n",
        "    loss_list, perplexity_list = [], []\n",
        "    hprev = np.zeros((self.n_h, 1))\n",
        "    N = len(encoded)\n",
        "    while iter_num < max_iter:\n",
        "        if pos + self.seq_length + 1 >= N or iter_num == 0:\n",
        "            hprev = np.zeros((self.n_h, 1)); pos = 0\n",
        "        inputs  = encoded[pos:pos+self.seq_length]\n",
        "        targets = encoded[pos+1:pos+self.seq_length+1]\n",
        "        pos += self.seq_length\n",
        "        loss, x, h, p = self.forward_pass(inputs, targets, hprev)\n",
        "        loss_list.append(loss)\n",
        "        perplexity_list.append(np.exp(loss / self.seq_length))\n",
        "        dWxh, dWhh, dWhy, dbh, dby = self.backpropagation(x, h, p, targets, clip=clip)\n",
        "        self.update_para(dWxh, dWhh, dWhy, dbh, dby)\n",
        "        hprev = h[self.seq_length - 1]\n",
        "        iter_num += 1\n",
        "    return loss_list, perplexity_list\n",
        "\n",
        "VanillaRNN.train_word = train_word\n",
        "\n",
        "def make_sample_words(self, hprev, seed_ix, n):\n",
        "    x = np.zeros((self.n_x, 1)); x[seed_ix] = 1\n",
        "    ixes, h = [], np.copy(hprev)\n",
        "    for _ in range(n):\n",
        "        h = np.tanh(self.Wxh @ x + self.Whh @ h + self.bh)\n",
        "        y = self.Why @ h + self.by\n",
        "        y -= np.max(y)                    \n",
        "        p = np.exp(y) / np.sum(np.exp(y))\n",
        "        ix = np.random.choice(range(self.n_x), p=p.ravel())\n",
        "        x = np.zeros((self.n_x, 1)); x[ix] = 1\n",
        "        ixes.append(ix)\n",
        "    return ixes\n",
        "\n",
        "VanillaRNN.make_sample_words = make_sample_words\n",
        "\n",
        "for seq_lengths_shakespeare, dataset_sizes_shakespeare, max_iters_shakespeare, clip_options_shakespeare in experiments_shakespeare:\n",
        "    print(f\"\\n=== Entrenando modelo (WORD-LEVEL) ===\")\n",
        "    print(f\"seq_length={seq_lengths_shakespeare}, dataset_size(tokens)={dataset_sizes_shakespeare}, max_iter={max_iters_shakespeare}, clip={clip_options_shakespeare}\")\n",
        "\n",
        "    subset_encoded = get_subset_tokens(encoded, dataset_sizes_shakespeare)\n",
        "    if len(subset_encoded) <= seq_lengths_shakespeare + 1:\n",
        "        print(\"→ Saltado: dataset_size <= seq_length+1\")\n",
        "        results.append({\n",
        "            \"seq_length\": seq_lengths_shakespeare, \"dataset_size\": dataset_sizes_shakespeare,\n",
        "            \"max_iter\": max_iters_shakespeare, \"clip\": clip_options_shakespeare, \"status\": \"skipped: dataset too small\"\n",
        "        })\n",
        "        continue\n",
        "\n",
        "    rnn = VanillaRNN(n_x=vocab_size, n_h=seq_lengths_shakespeare, seq_length=seq_lengths_shakespeare, learning_rate=0.05)\n",
        "\n",
        "    loss_list, perplexity_list = rnn.train_word(subset_encoded, max_iter=max_iters_shakespeare, clip=clip_options_shakespeare)\n",
        "\n",
        "    hprev = np.zeros((rnn.n_h, 1))\n",
        "    seed_word = \"the\" if \"the\" in word_to_int else next(iter(vocab))\n",
        "    seed_ix = word_to_int[seed_word]\n",
        "    sample_ix = rnn.make_sample_words(hprev, seed_ix, n=10)  # 10 palabras\n",
        "    generated = ' '.join(int_to_word[ix] for ix in sample_ix)\n",
        "\n",
        "    print(f\"→ Texto generado: {generated}\")\n",
        "\n",
        "    results.append({\n",
        "        \"seq_length\": seq_lengths_shakespeare,\n",
        "        \"dataset_size\": dataset_sizes_shakespeare,\n",
        "        \"max_iter\": max_iters_shakespeare,\n",
        "        \"clip\": clip_options_shakespeare,\n",
        "        \"generated\": generated,\n",
        "        \"final_loss\": float(loss_list[-1]),\n",
        "        \"final_perplexity\": float(perplexity_list[-1])\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FgWRcAnKSXv"
      },
      "source": [
        "NOTA: Para obtener sólo las gráficas para el punto 1, correr sólo las celdas: imports, classVanillaRNN y with open"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yABkLyQxW_jL",
        "outputId": "edf9fa5d-0d35-4413-c159-f014c8793ebb"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/input.txt'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#Change the path. This was coded in colab\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/content/input.txt\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      3\u001b[39m     text = f.read()\n\u001b[32m      5\u001b[39m chars = \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(text)))\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\laura\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:326\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    321\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    322\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    323\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    324\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/content/input.txt'"
          ]
        }
      ],
      "source": [
        "#Change the path. This was coded in colab\n",
        "with open('/content/input.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "char_to_int = {ch: i for i, ch in enumerate(chars)}\n",
        "int_to_char = {i: ch for i, ch in enumerate(chars)}\n",
        "vocab_size = len(chars)\n",
        "\n",
        "rnn = VanillaRNN(n_x=vocab_size, n_h=100, seq_length=25, learning_rate=1e-1)\n",
        "loss_list, perplexity_list = rnn.train(text, char_to_int, int_to_char, max_iter=5000, clip=True)\n",
        "\n",
        "\n",
        "rnn.plot_loss(loss_list)\n",
        "rnn.plot_perplexity(perplexity_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7wVwcC6jha_"
      },
      "source": [
        "This is the content used in input.txt:\n",
        "\n",
        "kmmatody: nomels bake tho pav.\n",
        "\n",
        "M:\n",
        "Atw: and I; thou onsel swere, lo! meroses ssseme noke shy ust but ker, woncter id imire ghy.\n",
        "\n",
        "What Thes hereth:\n",
        "Iss:\n",
        "Drou wort, netesteme here to whont toy,\n",
        "All My"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOrhK0OluzAJWppMiC/7jEn",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
